{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJmTiCK7L6bj"
   },
   "source": [
    "<h4>Authors Manisha Chandran and Vishwas Desai</h4>\n",
    "\n",
    "<h3>Deep neural Network</h3>\n",
    "<p>A simplistic representation of a Deep Neural Network is a hierarchical (layered) organization of neurons with connections to other neurons. Based on the received input, these neurons send a message or signal to other neurons, forming a complex network that learns through a feedback mechanism.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hungry-western"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import log_loss, r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "3oHNGdFlxcLX",
    "outputId": "134621d7-dae1-40e1-d4eb-d4fce33b1fb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-012f84e3-6915-4c05-a022-8da3463e5d87\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-012f84e3-6915-4c05-a022-8da3463e5d87\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trainset_2.csv to trainset_2.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "communist-stretch",
    "outputId": "6296686c-478e-4133-8e56-3b1b1ffd4355"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>box_office</th>\n",
       "      <th>positive_rate</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Musical</th>\n",
       "      <th>War</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Western</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>John Lasseter</th>\n",
       "      <th>Joe Johnston</th>\n",
       "      <th>Forest Whitaker</th>\n",
       "      <th>Michael Mann</th>\n",
       "      <th>Sydney Pollack</th>\n",
       "      <th>Peter Hyams</th>\n",
       "      <th>Martin Campbell</th>\n",
       "      <th>Rob Reiner</th>\n",
       "      <th>Mel Brooks</th>\n",
       "      <th>Ang Lee</th>\n",
       "      <th>Steve Oedekerk</th>\n",
       "      <th>Joseph Ruben</th>\n",
       "      <th>Barry Sonnenfeld</th>\n",
       "      <th>Richard Donner</th>\n",
       "      <th>John N. Smith</th>\n",
       "      <th>Terry Gilliam</th>\n",
       "      <th>...</th>\n",
       "      <th>Elodie Yung</th>\n",
       "      <th>Tsuwayuki Saotome</th>\n",
       "      <th>Taron Egerton</th>\n",
       "      <th>Edward Holcroft</th>\n",
       "      <th>Gordon Alexander</th>\n",
       "      <th>Joel Hogan</th>\n",
       "      <th>Josh Potthoff</th>\n",
       "      <th>Megan Peta Hill</th>\n",
       "      <th>Sarah Wright</th>\n",
       "      <th>Laurie Metcalf</th>\n",
       "      <th>Tracy Letts</th>\n",
       "      <th>Paapa Essiedu</th>\n",
       "      <th>Yassine Zeroual</th>\n",
       "      <th>Asan N'Jie</th>\n",
       "      <th>Anthony Gonzalez</th>\n",
       "      <th>Michael Stahl-David</th>\n",
       "      <th>Sally Hawkins</th>\n",
       "      <th>Jack Gore</th>\n",
       "      <th>Jet Jurgensmeyer</th>\n",
       "      <th>Nile Diaz</th>\n",
       "      <th>Lesley Manville</th>\n",
       "      <th>Lin Shaye</th>\n",
       "      <th>Walton Goggins</th>\n",
       "      <th>Storm Reid</th>\n",
       "      <th>Oprah Winfrey</th>\n",
       "      <th>Nick Robinson</th>\n",
       "      <th>Millicent Simmonds</th>\n",
       "      <th>Jóhannes Haukur Jóhannesson</th>\n",
       "      <th>Marcin Kowalczyk</th>\n",
       "      <th>John Cena</th>\n",
       "      <th>John Boyega</th>\n",
       "      <th>Cailee Spaeny</th>\n",
       "      <th>Rafe Spall</th>\n",
       "      <th>Sarah Vowell</th>\n",
       "      <th>Morena Baccarin</th>\n",
       "      <th>Joonas Suotamo</th>\n",
       "      <th>Lil Rel Howery</th>\n",
       "      <th>John David Washington</th>\n",
       "      <th>Isiah Whitlock Jr.</th>\n",
       "      <th>Amandla Stenberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.920930</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.340000e-07</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.431818</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>9.430000e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>2.920000e-08</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.946078</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.185185</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>3.130000e-08</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating    budget  ...  Isiah Whitlock Jr.  Amandla Stenberg\n",
       "0  3.920930  0.001000  ...                   0                 1\n",
       "1  3.431818  0.001666  ...                   0                 1\n",
       "2  2.357143  0.000533  ...                   0                 1\n",
       "3  3.946078  0.002000  ...                   0                 1\n",
       "4  3.185185  0.001933  ...                   0                 1\n",
       "\n",
       "[5 rows x 5055 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"trainset_2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "attended-albania",
    "outputId": "db5999d3-7aa4-4672-fbc2-04b61ef6e415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2818, 5054)\n",
      "(2818, 1)\n"
     ]
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('rating')\n",
    "cols\n",
    "X = np.array(df[cols])\n",
    "y = np.array(df[\"rating\"])\n",
    "y_shape = y.shape[0]\n",
    "y = np.reshape(y, (y_shape, 1))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uvu9VowPhJ1"
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w8G1ZJz34Py"
   },
   "source": [
    "## Our model\n",
    "\n",
    "\n",
    "- `Activation Function`: Each layer will have one or more neurons, each of which will compute a small function, such as the activation function. The signal to proceed to the next associated neurons is imitated by the activation function. The output is transferred if the incoming neurons produce a value greater than a threshold, otherwise it is ignored. We make us eof ReLu activation Function for our model\n",
    "\n",
    "- `L1 Loss Function`: L1 Loss Function is used to minimize the error which is the sum of the all the absolute differences between the true value and the predicted value. L1 loss function is preferered over other loss functions as it is not affected by outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tested-youth"
   },
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Converting to tensors\n",
    "\n",
    "def XtoTensor(array):\n",
    "    array = np.array(array, dtype=np.float32) \n",
    "    return Variable(torch.from_numpy(array)).type(torch.FloatTensor)\n",
    "\n",
    "def yToTensor(array):\n",
    "    array = np.array(array.astype(int))\n",
    "    return Variable(torch.from_numpy(array)).type(torch.FloatTensor)\n",
    "\n",
    "# X\n",
    "X_tensor_train = XtoTensor(X_train)\n",
    "X_tensor_test = XtoTensor(X_test)\n",
    "\n",
    "# y\n",
    "y_tensor_train = yToTensor(y_train)\n",
    "y_tensor_test = yToTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "absolute-oakland"
   },
   "outputs": [],
   "source": [
    "N_FEATURES = X_train.shape[1]\n",
    "# Neural Network Parameters\n",
    "\n",
    "X_tensor_train = X_tensor_train.cuda()\n",
    "X_tensor_test = X_tensor_test.cuda()\n",
    "y_tensor_train = y_tensor_train.cuda()\n",
    "y_tensor_test = y_tensor_test.cuda()\n",
    "\n",
    "dropout_proba = 0.9\n",
    "lr = 0.1\n",
    "momentum = 0.99\n",
    "dropout = torch.nn.Dropout(p=1 - (dropout_proba))\n",
    "dropout = dropout.cuda()\n",
    "# Hidden Layers\n",
    "\n",
    "hiddenLayer_1=5000\n",
    "hiddenLayer_2=1000\n",
    "hiddenLayer_3=200\n",
    "hiddenLayer_4=10\n",
    "\n",
    "# NN Layers\n",
    "\n",
    "linear_1=torch.nn.Linear(N_FEATURES, hiddenLayer_1, bias=True)\n",
    "linear_2=torch.nn.Linear(hiddenLayer_1, hiddenLayer_2)\n",
    "linear_3=torch.nn.Linear(hiddenLayer_2, hiddenLayer_3)\n",
    "linear_4=torch.nn.Linear(hiddenLayer_3, hiddenLayer_4)\n",
    "linear_5=torch.nn.Linear(hiddenLayer_4, 1)\n",
    "\n",
    "linear_1 = linear_1.cuda()\n",
    "linear_2 = linear_2.cuda()\n",
    "linear_3 = linear_3.cuda()\n",
    "linear_4 = linear_4.cuda()\n",
    "linear_5 = linear_5.cuda()\n",
    "\n",
    "# Activation Functions\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "# threshold = nn.Threshold(0.5, 0)\n",
    "# tanh= torch.nn.Tanh()\n",
    "relu= torch.nn.ReLU()\n",
    "# softmax = torch.nn.Softmax()\n",
    "\n",
    "relu = relu.cuda()\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "model = nn.Sequential(linear_1,nn.BatchNorm1d(hiddenLayer_1),relu,\n",
    "                          linear_2,dropout,relu,\n",
    "                          linear_3,dropout,relu,\n",
    "                          linear_4,dropout,relu,\n",
    "                          linear_5,dropout,relu,\n",
    "                          relu\n",
    "                          #sigmoid\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "copyrighted-benjamin",
    "outputId": "4e82b9d1-b705-451c-812c-6e09303a74c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27868.246\n",
      "Loss:6.640240669250488\n",
      "5 2.7675245\n",
      "Loss:7.794326305389404\n",
      "10 2.7675245\n",
      "Loss:7.794326305389404\n",
      "15 2.7675245\n",
      "Loss:7.794326305389404\n",
      "20 2.7675245\n",
      "Loss:7.794326305389404\n",
      "25 2.7675245\n",
      "Loss:7.794326305389404\n",
      "30 2.7675245\n",
      "Loss:7.794326305389404\n",
      "35 2.7675245\n",
      "Loss:7.794326305389404\n",
      "40 2.7675245\n",
      "Loss:7.794326305389404\n",
      "45 2.7675245\n",
      "Loss:7.794326305389404\n",
      "50 2.7675245\n",
      "Loss:7.794326305389404\n",
      "55 2.7675245\n",
      "Loss:7.794326305389404\n",
      "60 2.7675245\n",
      "Loss:7.794326305389404\n",
      "65 2.7675245\n",
      "Loss:7.794326305389404\n",
      "70 2.7675245\n",
      "Loss:7.794326305389404\n",
      "75 2.7675245\n",
      "Loss:7.794326305389404\n",
      "80 2.7675245\n",
      "Loss:7.794326305389404\n",
      "85 2.7675245\n",
      "Loss:7.794326305389404\n",
      "90 2.7675245\n",
      "Loss:7.794326305389404\n",
      "95 2.7675245\n",
      "Loss:7.794326305389404\n",
      "100 2.7675245\n",
      "Loss:7.794326305389404\n",
      "105 2.7675245\n",
      "Loss:7.794326305389404\n",
      "110 2.7675245\n",
      "Loss:7.794326305389404\n",
      "115 2.7675245\n",
      "Loss:7.794326305389404\n",
      "120 2.7675245\n",
      "Loss:7.794326305389404\n",
      "125 2.7675245\n",
      "Loss:7.794326305389404\n",
      "130 2.7675245\n",
      "Loss:7.794326305389404\n",
      "135 2.7675245\n",
      "Loss:7.794326305389404\n",
      "140 2.7675245\n",
      "Loss:7.794326305389404\n",
      "145 2.7675245\n",
      "Loss:7.794326305389404\n",
      "150 2.7675245\n",
      "Loss:7.794326305389404\n",
      "155 2.7675245\n",
      "Loss:7.794326305389404\n",
      "160 2.7675245\n",
      "Loss:7.794326305389404\n",
      "165 2.7675245\n",
      "Loss:7.794326305389404\n",
      "170 2.7675245\n",
      "Loss:7.794326305389404\n",
      "175 2.7675245\n",
      "Loss:7.794326305389404\n",
      "180 2.7675245\n",
      "Loss:7.794326305389404\n",
      "185 2.7675245\n",
      "Loss:7.794326305389404\n",
      "190 2.7675245\n",
      "Loss:7.794326305389404\n",
      "195 2.7675245\n",
      "Loss:7.794326305389404\n",
      "200 2.7675245\n",
      "Loss:7.794326305389404\n",
      "205 2.7675245\n",
      "Loss:7.794326305389404\n",
      "210 2.7675245\n",
      "Loss:7.794326305389404\n",
      "215 2.7675245\n",
      "Loss:7.794326305389404\n",
      "220 2.7675245\n",
      "Loss:7.794326305389404\n",
      "225 2.7675245\n",
      "Loss:7.794326305389404\n",
      "230 2.7675245\n",
      "Loss:7.794326305389404\n",
      "235 2.7675245\n",
      "Loss:7.794326305389404\n",
      "240 2.7675245\n",
      "Loss:7.794326305389404\n",
      "245 2.7675245\n",
      "Loss:7.794326305389404\n",
      "250 2.7675245\n",
      "Loss:7.794326305389404\n",
      "255 2.7675245\n",
      "Loss:7.794326305389404\n",
      "260 2.7675245\n",
      "Loss:7.794326305389404\n",
      "265 2.7675245\n",
      "Loss:7.794326305389404\n",
      "270 2.7675245\n",
      "Loss:7.794326305389404\n",
      "275 2.7675245\n",
      "Loss:7.794326305389404\n",
      "280 2.7675245\n",
      "Loss:7.794326305389404\n",
      "285 2.7675245\n",
      "Loss:7.794326305389404\n",
      "290 2.7675245\n",
      "Loss:7.794326305389404\n",
      "295 2.7675245\n",
      "Loss:7.794326305389404\n",
      "300 2.7675245\n",
      "Loss:7.794326305389404\n",
      "305 2.7675245\n",
      "Loss:7.794326305389404\n",
      "310 2.7675245\n",
      "Loss:7.794326305389404\n",
      "315 2.7675245\n",
      "Loss:7.794326305389404\n",
      "320 2.7675245\n",
      "Loss:7.794326305389404\n",
      "325 2.7675245\n",
      "Loss:7.794326305389404\n",
      "330 2.7675245\n",
      "Loss:7.794326305389404\n",
      "335 2.7675245\n",
      "Loss:7.794326305389404\n",
      "340 2.7675245\n",
      "Loss:7.794326305389404\n",
      "345 2.7675245\n",
      "Loss:7.794326305389404\n",
      "350 2.7675245\n",
      "Loss:7.794326305389404\n",
      "355 2.7675245\n",
      "Loss:7.794326305389404\n",
      "360 2.7675245\n",
      "Loss:7.794326305389404\n",
      "365 2.7675245\n",
      "Loss:7.794326305389404\n",
      "370 2.7675245\n",
      "Loss:7.794326305389404\n",
      "375 2.7675245\n",
      "Loss:7.794326305389404\n",
      "380 2.7675245\n",
      "Loss:7.794326305389404\n",
      "385 2.7675245\n",
      "Loss:7.794326305389404\n",
      "390 2.7675245\n",
      "Loss:7.794326305389404\n",
      "395 2.7675245\n",
      "Loss:7.794326305389404\n",
      "400 2.7675245\n",
      "Loss:7.794326305389404\n",
      "405 2.7675245\n",
      "Loss:7.794326305389404\n",
      "410 2.7675245\n",
      "Loss:7.794326305389404\n",
      "415 2.7675245\n",
      "Loss:7.794326305389404\n",
      "420 2.7675245\n",
      "Loss:7.794326305389404\n",
      "425 2.7675245\n",
      "Loss:7.794326305389404\n",
      "430 2.7675245\n",
      "Loss:7.794326305389404\n",
      "435 2.7675245\n",
      "Loss:7.794326305389404\n",
      "440 2.7675245\n",
      "Loss:7.794326305389404\n",
      "445 2.7675245\n",
      "Loss:7.794326305389404\n",
      "450 2.7675245\n",
      "Loss:7.794326305389404\n",
      "455 2.7675245\n",
      "Loss:7.794326305389404\n",
      "460 2.7675245\n",
      "Loss:7.794326305389404\n",
      "465 2.7675245\n",
      "Loss:7.794326305389404\n",
      "470 2.7675245\n",
      "Loss:7.794326305389404\n",
      "475 2.7675245\n",
      "Loss:7.794326305389404\n",
      "480 2.7675245\n",
      "Loss:7.794326305389404\n",
      "485 2.7675245\n",
      "Loss:7.794326305389404\n",
      "490 2.7675245\n",
      "Loss:7.794326305389404\n",
      "495 2.7675245\n",
      "Loss:7.794326305389404\n",
      "500 2.7675245\n",
      "Loss:7.794326305389404\n",
      "505 2.7675245\n",
      "Loss:7.794326305389404\n",
      "510 2.7675245\n",
      "Loss:7.794326305389404\n",
      "515 2.7675245\n",
      "Loss:7.794326305389404\n",
      "520 2.7675245\n",
      "Loss:7.794326305389404\n",
      "525 2.7675245\n",
      "Loss:7.794326305389404\n",
      "530 2.7675245\n",
      "Loss:7.794326305389404\n",
      "535 2.7675245\n",
      "Loss:7.794326305389404\n",
      "540 2.7675245\n",
      "Loss:7.794326305389404\n",
      "545 2.7675245\n",
      "Loss:7.794326305389404\n",
      "550 2.7675245\n",
      "Loss:7.794326305389404\n",
      "555 2.7675245\n",
      "Loss:7.794326305389404\n",
      "560 2.7675245\n",
      "Loss:7.794326305389404\n",
      "565 2.7675245\n",
      "Loss:7.794326305389404\n",
      "570 2.7675245\n",
      "Loss:7.794326305389404\n",
      "575 2.7675245\n",
      "Loss:7.794326305389404\n",
      "580 2.7675245\n",
      "Loss:7.794326305389404\n",
      "585 2.7675245\n",
      "Loss:7.794326305389404\n",
      "590 2.7675245\n",
      "Loss:7.794326305389404\n",
      "595 2.7675245\n",
      "Loss:7.794326305389404\n",
      "600 2.7675245\n",
      "Loss:7.794326305389404\n",
      "605 2.7675245\n",
      "Loss:7.794326305389404\n",
      "610 2.7675245\n",
      "Loss:7.794326305389404\n",
      "615 2.7675245\n",
      "Loss:7.794326305389404\n",
      "620 2.7675245\n",
      "Loss:7.794326305389404\n",
      "625 2.7675245\n",
      "Loss:7.794326305389404\n",
      "630 2.7675245\n",
      "Loss:7.794326305389404\n",
      "635 2.7675245\n",
      "Loss:7.794326305389404\n",
      "640 2.7675245\n",
      "Loss:7.794326305389404\n",
      "645 2.7675245\n",
      "Loss:7.794326305389404\n",
      "650 2.7675245\n",
      "Loss:7.794326305389404\n",
      "655 2.7675245\n",
      "Loss:7.794326305389404\n",
      "660 2.7675245\n",
      "Loss:7.794326305389404\n",
      "665 2.7675245\n",
      "Loss:7.794326305389404\n",
      "670 2.7675245\n",
      "Loss:7.794326305389404\n",
      "675 2.7675245\n",
      "Loss:7.794326305389404\n",
      "680 2.7675245\n",
      "Loss:7.794326305389404\n",
      "685 2.7675245\n",
      "Loss:7.794326305389404\n",
      "690 2.7675245\n",
      "Loss:7.794326305389404\n",
      "695 2.7675245\n",
      "Loss:7.794326305389404\n",
      "700 2.7675245\n",
      "Loss:7.794326305389404\n",
      "705 2.7675245\n",
      "Loss:7.794326305389404\n",
      "710 2.7675245\n",
      "Loss:7.794326305389404\n",
      "715 2.7675245\n",
      "Loss:7.794326305389404\n",
      "720 2.7675245\n",
      "Loss:7.794326305389404\n",
      "725 2.7675245\n",
      "Loss:7.794326305389404\n",
      "730 2.7675245\n",
      "Loss:7.794326305389404\n",
      "735 2.7675245\n",
      "Loss:7.794326305389404\n",
      "740 2.7675245\n",
      "Loss:7.794326305389404\n",
      "745 2.7675245\n",
      "Loss:7.794326305389404\n",
      "750 2.7675245\n",
      "Loss:7.794326305389404\n",
      "755 2.7675245\n",
      "Loss:7.794326305389404\n",
      "760 2.7675245\n",
      "Loss:7.794326305389404\n",
      "765 2.7675245\n",
      "Loss:7.794326305389404\n",
      "770 2.7675245\n",
      "Loss:7.794326305389404\n",
      "775 2.7675245\n",
      "Loss:7.794326305389404\n",
      "780 2.7675245\n",
      "Loss:7.794326305389404\n",
      "785 2.7675245\n",
      "Loss:7.794326305389404\n",
      "790 2.7675245\n",
      "Loss:7.794326305389404\n",
      "795 2.7675245\n",
      "Loss:7.794326305389404\n",
      "800 2.7675245\n",
      "Loss:7.794326305389404\n",
      "805 2.7675245\n",
      "Loss:7.794326305389404\n",
      "810 2.7675245\n",
      "Loss:7.794326305389404\n",
      "815 2.7675245\n",
      "Loss:7.794326305389404\n",
      "820 2.7675245\n",
      "Loss:7.794326305389404\n",
      "825 2.7675245\n",
      "Loss:7.794326305389404\n",
      "830 2.7675245\n",
      "Loss:7.794326305389404\n",
      "835 2.7675245\n",
      "Loss:7.794326305389404\n",
      "840 2.7675245\n",
      "Loss:7.794326305389404\n",
      "845 2.7675245\n",
      "Loss:7.794326305389404\n",
      "850 2.7675245\n",
      "Loss:7.794326305389404\n",
      "855 2.7675245\n",
      "Loss:7.794326305389404\n",
      "860 2.7675245\n",
      "Loss:7.794326305389404\n",
      "865 2.7675245\n",
      "Loss:7.794326305389404\n",
      "870 2.7675245\n",
      "Loss:7.794326305389404\n",
      "875 2.7675245\n",
      "Loss:7.794326305389404\n",
      "880 2.7675245\n",
      "Loss:7.794326305389404\n",
      "885 2.7675245\n",
      "Loss:7.794326305389404\n",
      "890 2.7675245\n",
      "Loss:7.794326305389404\n",
      "895 2.7675245\n",
      "Loss:7.794326305389404\n",
      "900 2.7675245\n",
      "Loss:7.794326305389404\n",
      "905 2.7675245\n",
      "Loss:7.794326305389404\n",
      "910 2.7675245\n",
      "Loss:7.794326305389404\n",
      "915 2.7675245\n",
      "Loss:7.794326305389404\n",
      "920 2.7675245\n",
      "Loss:7.794326305389404\n",
      "925 2.7675245\n",
      "Loss:7.794326305389404\n",
      "930 2.7675245\n",
      "Loss:7.794326305389404\n",
      "935 2.7675245\n",
      "Loss:7.794326305389404\n",
      "940 2.7675245\n",
      "Loss:7.794326305389404\n",
      "945 2.7675245\n",
      "Loss:7.794326305389404\n",
      "950 2.7675245\n",
      "Loss:7.794326305389404\n",
      "955 2.7675245\n",
      "Loss:7.794326305389404\n",
      "960 2.7675245\n",
      "Loss:7.794326305389404\n",
      "965 2.7675245\n",
      "Loss:7.794326305389404\n",
      "970 2.7675245\n",
      "Loss:7.794326305389404\n",
      "975 2.7675245\n",
      "Loss:7.794326305389404\n",
      "980 2.7675245\n",
      "Loss:7.794326305389404\n",
      "985 2.7675245\n",
      "Loss:7.794326305389404\n",
      "990 2.7675245\n",
      "Loss:7.794326305389404\n",
      "995 2.7675245\n",
      "Loss:7.794326305389404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "loss_function=torch.nn.L1Loss()\n",
    "epochs = 1000\n",
    "losses = []\n",
    "# model.to(torch.device(\"cuda:0\"))\n",
    "model = model.cuda()\n",
    "# optimizer = optimizer.cuda()\n",
    "# loss_function = loss_function.cuda()\n",
    "\n",
    "for step in range(epochs):    \n",
    "    out = model(X_tensor_train) \n",
    "    # y_tensor_train = tf.squeeze(y_tensor_train)\n",
    "    target = y_tensor_train\n",
    "    # target = target.unsqueeze(1)\n",
    "    # target = target.float()\n",
    "    cost = loss_function(out, target) \n",
    "    optimizer.zero_grad()  \n",
    "    # BackProp \n",
    "    cost.backward()   \n",
    "    # adjusting the weights     \n",
    "    optimizer.step()         \n",
    "        \n",
    "    if step % 5 == 0:        \n",
    "        loss = cost.data\n",
    "        losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())        \n",
    "        prediction = (model(X_tensor_test).data).float()      \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = y_tensor_test.cpu().data.numpy()\n",
    "        print(\"Loss:\" + str(torch.mean((y_tensor_test.cpu() - pred_y) **2).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "embedded-hungarian",
    "outputId": "8412ba3e-8f93-497a-f42b-26f16bc2e139"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "R2: -12.69137652845198\n",
      "MSE: 7.7943263\n"
     ]
    }
   ],
   "source": [
    "# Graph\n",
    "%matplotlib inline\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "pred_y = pred_y > 0.5\n",
    "# print('f1 score', f1_score(target_y, pred_y))\n",
    "\n",
    "print(\"--\"*25)\n",
    "# R2 \n",
    "print('R2:',r2_score(target_y, pred_y))\n",
    "print(\"MSE:\",mean_squared_error(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd4PiwSvPdf_"
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nesINpEm1iW_"
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "The process of determining the best combination of hyperparameters that enables the model to work at its best is known as hyperparameter tuning. The only way to get the best results out of models is to use the right combination of hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH8ztkIA2tst"
   },
   "source": [
    "#### For `dropout` = 0.5, `learning rate` = 0.01, `momentum` = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VkRExf2d1glc",
    "outputId": "bcc873ff-bdd6-4470-faef-4116853c8732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.6951344\n",
      "Loss:6379.638671875\n",
      "5 2.2593787\n",
      "Loss:6.525671482086182\n",
      "10 2.5965044\n",
      "Loss:6.661040306091309\n",
      "15 2.3741107\n",
      "Loss:6.223891735076904\n",
      "20 2.0990746\n",
      "Loss:5.364850997924805\n",
      "25 2.0528934\n",
      "Loss:5.271401882171631\n",
      "30 2.0742111\n",
      "Loss:5.081155300140381\n",
      "35 2.002137\n",
      "Loss:5.243777751922607\n",
      "40 1.9969049\n",
      "Loss:5.039491176605225\n",
      "45 1.9399694\n",
      "Loss:4.785374641418457\n",
      "50 1.9311216\n",
      "Loss:5.0354719161987305\n",
      "55 1.8810362\n",
      "Loss:4.913243770599365\n",
      "60 1.8307346\n",
      "Loss:5.044691562652588\n",
      "65 1.8496295\n",
      "Loss:4.63255500793457\n",
      "70 1.8433352\n",
      "Loss:4.587392807006836\n",
      "75 1.7578613\n",
      "Loss:4.455867767333984\n",
      "80 1.7870789\n",
      "Loss:4.543249607086182\n",
      "85 1.7433765\n",
      "Loss:4.372928619384766\n",
      "90 1.7547187\n",
      "Loss:4.176758289337158\n",
      "95 1.7187438\n",
      "Loss:4.171981334686279\n",
      "100 1.7170476\n",
      "Loss:4.254055976867676\n",
      "105 1.6691493\n",
      "Loss:4.674685001373291\n",
      "110 1.6853058\n",
      "Loss:4.122927188873291\n",
      "115 1.672367\n",
      "Loss:4.263768196105957\n",
      "120 1.7028421\n",
      "Loss:4.298427581787109\n",
      "125 1.6579062\n",
      "Loss:4.3647379875183105\n",
      "130 1.6407229\n",
      "Loss:4.455217361450195\n",
      "135 1.6637756\n",
      "Loss:4.559031963348389\n",
      "140 1.6554741\n",
      "Loss:4.016328811645508\n",
      "145 1.676854\n",
      "Loss:4.2579498291015625\n",
      "150 1.6781373\n",
      "Loss:4.131227493286133\n",
      "155 1.6503576\n",
      "Loss:4.121610164642334\n",
      "160 1.6595589\n",
      "Loss:4.0278425216674805\n",
      "165 1.64181\n",
      "Loss:4.176403045654297\n",
      "170 1.647506\n",
      "Loss:4.14434814453125\n",
      "175 1.585609\n",
      "Loss:4.272909164428711\n",
      "180 1.61791\n",
      "Loss:4.086862087249756\n",
      "185 1.5845158\n",
      "Loss:4.0887603759765625\n",
      "190 1.6453745\n",
      "Loss:4.370459079742432\n",
      "195 1.6499659\n",
      "Loss:4.0408759117126465\n",
      "200 1.686407\n",
      "Loss:4.148088455200195\n",
      "205 1.6286167\n",
      "Loss:4.016758441925049\n",
      "210 1.6555443\n",
      "Loss:4.088191509246826\n",
      "215 1.6478089\n",
      "Loss:4.374582767486572\n",
      "220 1.6268309\n",
      "Loss:4.162586688995361\n",
      "225 1.6207972\n",
      "Loss:4.316267490386963\n",
      "230 1.6716038\n",
      "Loss:4.658176422119141\n",
      "235 1.6007324\n",
      "Loss:4.315520286560059\n",
      "240 1.6635046\n",
      "Loss:4.456153869628906\n",
      "245 1.6298683\n",
      "Loss:4.466224193572998\n",
      "250 1.6281722\n",
      "Loss:4.425332546234131\n",
      "255 1.6227471\n",
      "Loss:4.137228012084961\n",
      "260 1.645436\n",
      "Loss:4.182589054107666\n",
      "265 1.5848166\n",
      "Loss:4.177483558654785\n",
      "270 1.583498\n",
      "Loss:4.16654109954834\n",
      "275 1.576599\n",
      "Loss:4.177851676940918\n",
      "280 1.6461815\n",
      "Loss:3.902169942855835\n",
      "285 1.5912298\n",
      "Loss:4.554399490356445\n",
      "290 1.5914915\n",
      "Loss:4.124642372131348\n",
      "295 1.5864974\n",
      "Loss:4.135413646697998\n",
      "300 1.6437001\n",
      "Loss:4.0074005126953125\n",
      "305 1.5756669\n",
      "Loss:4.263615608215332\n",
      "310 1.6568947\n",
      "Loss:4.481904983520508\n",
      "315 1.6662784\n",
      "Loss:4.338646411895752\n",
      "320 1.5854563\n",
      "Loss:4.192869663238525\n",
      "325 1.5734516\n",
      "Loss:4.186676979064941\n",
      "330 1.5765231\n",
      "Loss:4.302135944366455\n",
      "335 1.547315\n",
      "Loss:4.1968159675598145\n",
      "340 1.5991399\n",
      "Loss:4.45979118347168\n",
      "345 1.5431322\n",
      "Loss:4.398990154266357\n",
      "350 1.5661427\n",
      "Loss:3.926332712173462\n",
      "355 1.5811834\n",
      "Loss:4.340305805206299\n",
      "360 1.5709738\n",
      "Loss:4.13994026184082\n",
      "365 1.564376\n",
      "Loss:4.221909046173096\n",
      "370 1.5344824\n",
      "Loss:4.574368476867676\n",
      "375 1.551385\n",
      "Loss:4.144657135009766\n",
      "380 1.5845451\n",
      "Loss:4.475358009338379\n",
      "385 1.573059\n",
      "Loss:4.3632683753967285\n",
      "390 1.6076797\n",
      "Loss:4.40361213684082\n",
      "395 1.5762331\n",
      "Loss:4.170220851898193\n",
      "400 1.5475866\n",
      "Loss:4.163801193237305\n",
      "405 1.6045746\n",
      "Loss:4.270436763763428\n",
      "410 1.5588214\n",
      "Loss:4.265036106109619\n",
      "415 1.602105\n",
      "Loss:4.327232360839844\n",
      "420 1.5385759\n",
      "Loss:4.29421329498291\n",
      "425 1.5874512\n",
      "Loss:4.347141265869141\n",
      "430 1.4742022\n",
      "Loss:3.985553026199341\n",
      "435 1.5983272\n",
      "Loss:4.458662033081055\n",
      "440 1.5797892\n",
      "Loss:4.218374729156494\n",
      "445 1.5596095\n",
      "Loss:4.157846450805664\n",
      "450 1.5337846\n",
      "Loss:4.332347393035889\n",
      "455 1.5794247\n",
      "Loss:4.336050033569336\n",
      "460 1.5797039\n",
      "Loss:4.343067169189453\n",
      "465 1.5629238\n",
      "Loss:4.1985554695129395\n",
      "470 1.5543079\n",
      "Loss:4.306346893310547\n",
      "475 1.578461\n",
      "Loss:4.544191837310791\n",
      "480 1.5610622\n",
      "Loss:4.101583480834961\n",
      "485 1.5297648\n",
      "Loss:4.220208644866943\n",
      "490 1.5372849\n",
      "Loss:4.147862434387207\n",
      "495 1.52278\n",
      "Loss:4.0748114585876465\n",
      "500 1.5972605\n",
      "Loss:4.521665096282959\n",
      "505 1.587346\n",
      "Loss:4.149991035461426\n",
      "510 1.6120939\n",
      "Loss:4.409904956817627\n",
      "515 1.5362252\n",
      "Loss:4.077707767486572\n",
      "520 1.5668343\n",
      "Loss:4.317679405212402\n",
      "525 1.5486956\n",
      "Loss:4.239826202392578\n",
      "530 1.5165249\n",
      "Loss:4.208680152893066\n",
      "535 1.5583531\n",
      "Loss:4.5069756507873535\n",
      "540 1.5189862\n",
      "Loss:4.215815544128418\n",
      "545 1.5607135\n",
      "Loss:4.301185131072998\n",
      "550 1.5573193\n",
      "Loss:4.336624622344971\n",
      "555 1.5989697\n",
      "Loss:4.2170281410217285\n",
      "560 1.5431938\n",
      "Loss:4.121493816375732\n",
      "565 1.5243785\n",
      "Loss:4.389508247375488\n",
      "570 1.5690194\n",
      "Loss:4.323616981506348\n",
      "575 1.5746391\n",
      "Loss:3.907874584197998\n",
      "580 1.5950494\n",
      "Loss:4.52742862701416\n",
      "585 1.531295\n",
      "Loss:4.219435691833496\n",
      "590 1.5689651\n",
      "Loss:4.298886775970459\n",
      "595 1.583195\n",
      "Loss:4.168737411499023\n",
      "600 1.53413\n",
      "Loss:4.276798725128174\n",
      "605 1.6006382\n",
      "Loss:4.316092014312744\n",
      "610 1.5869267\n",
      "Loss:4.402123928070068\n",
      "615 1.5740466\n",
      "Loss:4.34738302230835\n",
      "620 1.5113847\n",
      "Loss:4.332046985626221\n",
      "625 1.549542\n",
      "Loss:4.118523120880127\n",
      "630 1.5276891\n",
      "Loss:3.978670835494995\n",
      "635 1.5875942\n",
      "Loss:4.299884796142578\n",
      "640 1.5588582\n",
      "Loss:4.185862064361572\n",
      "645 1.604682\n",
      "Loss:4.21807861328125\n",
      "650 1.5565838\n",
      "Loss:4.316415309906006\n",
      "655 1.5484896\n",
      "Loss:4.303300857543945\n",
      "660 1.5545404\n",
      "Loss:4.093592166900635\n",
      "665 1.5493755\n",
      "Loss:4.350789546966553\n",
      "670 1.5249615\n",
      "Loss:4.407863140106201\n",
      "675 1.5658412\n",
      "Loss:4.432932376861572\n",
      "680 1.5318466\n",
      "Loss:3.9966964721679688\n",
      "685 1.5614587\n",
      "Loss:4.526117324829102\n",
      "690 1.5430739\n",
      "Loss:4.20628023147583\n",
      "695 1.5636209\n",
      "Loss:4.23907995223999\n",
      "700 1.5001966\n",
      "Loss:4.019350528717041\n",
      "705 1.5385784\n",
      "Loss:4.182412147521973\n",
      "710 1.5685143\n",
      "Loss:4.371259689331055\n",
      "715 1.5905393\n",
      "Loss:4.339221954345703\n",
      "720 1.5678045\n",
      "Loss:4.155738830566406\n",
      "725 1.5025795\n",
      "Loss:4.280905246734619\n",
      "730 1.5265056\n",
      "Loss:4.16166877746582\n",
      "735 1.5358844\n",
      "Loss:4.45519495010376\n",
      "740 1.6099812\n",
      "Loss:4.298800468444824\n",
      "745 1.5421324\n",
      "Loss:4.0078301429748535\n",
      "750 1.5657282\n",
      "Loss:4.247382164001465\n",
      "755 1.6006966\n",
      "Loss:4.0752081871032715\n",
      "760 1.5727894\n",
      "Loss:4.383246898651123\n",
      "765 1.5460594\n",
      "Loss:4.1823835372924805\n",
      "770 1.5475628\n",
      "Loss:4.377289772033691\n",
      "775 1.5527923\n",
      "Loss:4.145445823669434\n",
      "780 1.5344651\n",
      "Loss:4.4940290451049805\n",
      "785 1.5943779\n",
      "Loss:4.263866901397705\n",
      "790 1.5557048\n",
      "Loss:4.160270690917969\n",
      "795 1.5801897\n",
      "Loss:4.62454080581665\n",
      "800 1.4937634\n",
      "Loss:3.998276948928833\n",
      "805 1.555222\n",
      "Loss:4.353405475616455\n",
      "810 1.6058524\n",
      "Loss:4.365337371826172\n",
      "815 1.5178994\n",
      "Loss:4.492450714111328\n",
      "820 1.5315204\n",
      "Loss:4.206020355224609\n",
      "825 1.5559057\n",
      "Loss:4.50726842880249\n",
      "830 1.6045742\n",
      "Loss:4.434859275817871\n",
      "835 1.5135615\n",
      "Loss:4.237253665924072\n",
      "840 1.5543044\n",
      "Loss:4.060973644256592\n",
      "845 1.5290695\n",
      "Loss:4.35727071762085\n",
      "850 1.5799525\n",
      "Loss:4.3091840744018555\n",
      "855 1.5742897\n",
      "Loss:4.1542816162109375\n",
      "860 1.5396869\n",
      "Loss:4.4301605224609375\n",
      "865 1.5566133\n",
      "Loss:4.140364646911621\n",
      "870 1.5551169\n",
      "Loss:4.250553131103516\n",
      "875 1.5709808\n",
      "Loss:4.275198459625244\n",
      "880 1.5494013\n",
      "Loss:4.113558769226074\n",
      "885 1.5557157\n",
      "Loss:4.196296691894531\n",
      "890 1.5441197\n",
      "Loss:4.194920063018799\n",
      "895 1.6134188\n",
      "Loss:4.345879554748535\n",
      "900 1.572769\n",
      "Loss:4.206350326538086\n",
      "905 1.5367253\n",
      "Loss:4.350148677825928\n",
      "910 1.5862885\n",
      "Loss:4.2127885818481445\n",
      "915 1.5429525\n",
      "Loss:4.215798377990723\n",
      "920 1.5437437\n",
      "Loss:4.142913818359375\n",
      "925 1.6111552\n",
      "Loss:4.376946926116943\n",
      "930 1.5389742\n",
      "Loss:4.032120704650879\n",
      "935 1.5775739\n",
      "Loss:4.649516582489014\n",
      "940 1.5992253\n",
      "Loss:4.074278831481934\n",
      "945 1.5464058\n",
      "Loss:4.184473991394043\n",
      "950 1.559457\n",
      "Loss:4.4560675621032715\n",
      "955 1.5328684\n",
      "Loss:4.1650919914245605\n",
      "960 1.5586437\n",
      "Loss:4.354320049285889\n",
      "965 1.5567089\n",
      "Loss:4.328780174255371\n",
      "970 1.56411\n",
      "Loss:4.428198337554932\n",
      "975 1.5930902\n",
      "Loss:4.384792327880859\n",
      "980 1.5941192\n",
      "Loss:4.219029903411865\n",
      "985 1.5426869\n",
      "Loss:4.29237174987793\n",
      "990 1.5278081\n",
      "Loss:4.382420539855957\n",
      "995 1.5773834\n",
      "Loss:4.411577224731445\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "R2: -8.972654150159974\n",
      "MSE: 5.6773047\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = X_train.shape[1]\n",
    "# Neural Network Parameters\n",
    "\n",
    "X_tensor_train = X_tensor_train.cuda()\n",
    "X_tensor_test = X_tensor_test.cuda()\n",
    "y_tensor_train = y_tensor_train.cuda()\n",
    "y_tensor_test = y_tensor_test.cuda()\n",
    "\n",
    "dropout_proba = 0.5\n",
    "lr = 0.01\n",
    "momentum = 0.55\n",
    "dropout = torch.nn.Dropout(p=1 - (dropout_proba))\n",
    "dropout = dropout.cuda()\n",
    "# Hidden Layers\n",
    "\n",
    "hiddenLayer_1=5000\n",
    "hiddenLayer_2=1000\n",
    "hiddenLayer_3=200\n",
    "hiddenLayer_4=10\n",
    "\n",
    "# NN Layers\n",
    "\n",
    "linear_1=torch.nn.Linear(N_FEATURES, hiddenLayer_1, bias=True)\n",
    "linear_2=torch.nn.Linear(hiddenLayer_1, hiddenLayer_2)\n",
    "linear_3=torch.nn.Linear(hiddenLayer_2, hiddenLayer_3)\n",
    "linear_4=torch.nn.Linear(hiddenLayer_3, hiddenLayer_4)\n",
    "linear_5=torch.nn.Linear(hiddenLayer_4, 1)\n",
    "\n",
    "linear_1 = linear_1.cuda()\n",
    "linear_2 = linear_2.cuda()\n",
    "linear_3 = linear_3.cuda()\n",
    "linear_4 = linear_4.cuda()\n",
    "linear_5 = linear_5.cuda()\n",
    "\n",
    "# Activation Functions\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "# threshold = nn.Threshold(0.5, 0)\n",
    "# tanh= torch.nn.Tanh()\n",
    "relu= torch.nn.ReLU()\n",
    "# softmax = torch.nn.Softmax()\n",
    "\n",
    "relu = relu.cuda()\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "model = nn.Sequential(linear_1,nn.BatchNorm1d(hiddenLayer_1),relu,\n",
    "                          linear_2,dropout,relu,\n",
    "                          linear_3,dropout,relu,\n",
    "                          linear_4,dropout,relu,\n",
    "                          linear_5,dropout,relu,\n",
    "                          relu\n",
    "                          #sigmoid\n",
    "                          )\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "loss_function=torch.nn.L1Loss()\n",
    "epochs = 1000\n",
    "losses = []\n",
    "# model.to(torch.device(\"cuda:0\"))\n",
    "model = model.cuda()\n",
    "# optimizer = optimizer.cuda()\n",
    "# loss_function = loss_function.cuda()\n",
    "\n",
    "for step in range(epochs):    \n",
    "    out = model(X_tensor_train) \n",
    "    # y_tensor_train = tf.squeeze(y_tensor_train)\n",
    "    target = y_tensor_train\n",
    "    # target = target.unsqueeze(1)\n",
    "    # target = target.float()\n",
    "    cost = loss_function(out, target) \n",
    "    optimizer.zero_grad()  \n",
    "    # BackProp \n",
    "    cost.backward()   \n",
    "    # adjusting the weights     \n",
    "    optimizer.step()         \n",
    "        \n",
    "    if step % 5 == 0:        \n",
    "        loss = cost.data\n",
    "        losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())        \n",
    "        prediction = (model(X_tensor_test).data).float()      \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = y_tensor_test.cpu().data.numpy()\n",
    "        print(\"Loss:\" + str(torch.mean((y_tensor_test.cpu() - pred_y) **2).detach().item()))\n",
    "\n",
    "\n",
    "print(\"--\"*25)\n",
    "# Graph\n",
    "%matplotlib inline\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "pred_y = pred_y > 0.5\n",
    "# print('f1 score', f1_score(target_y, pred_y))\n",
    "\n",
    "print(\"--\"*25)\n",
    "# R2 \n",
    "print('R2:',r2_score(target_y, pred_y))\n",
    "print(\"MSE:\",mean_squared_error(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTjBgbK3Fpx"
   },
   "source": [
    "#### For `dropout` = 0.3, `learning rate` = 0.001, `momentum` = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Twi7iv002JFJ",
    "outputId": "a77d068f-c963-4eb0-b5df-61f99e530dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.613501\n",
      "Loss:19.95604705810547\n",
      "5 2.44582\n",
      "Loss:6.710725784301758\n",
      "10 2.4404016\n",
      "Loss:6.260131359100342\n",
      "15 2.41821\n",
      "Loss:6.267601013183594\n",
      "20 2.3764386\n",
      "Loss:6.347190856933594\n",
      "25 2.364204\n",
      "Loss:6.273499965667725\n",
      "30 2.3764493\n",
      "Loss:6.314511299133301\n",
      "35 2.3534489\n",
      "Loss:6.292153358459473\n",
      "40 2.3393178\n",
      "Loss:6.366074562072754\n",
      "45 2.343541\n",
      "Loss:6.448794364929199\n",
      "50 2.288811\n",
      "Loss:6.149898052215576\n",
      "55 2.2904277\n",
      "Loss:6.279263973236084\n",
      "60 2.3160617\n",
      "Loss:6.466237545013428\n",
      "65 2.3277016\n",
      "Loss:6.193740367889404\n",
      "70 2.331949\n",
      "Loss:6.050112247467041\n",
      "75 2.3053746\n",
      "Loss:6.212640285491943\n",
      "80 2.3258986\n",
      "Loss:6.094221115112305\n",
      "85 2.3154204\n",
      "Loss:6.103962421417236\n",
      "90 2.268919\n",
      "Loss:6.2217326164245605\n",
      "95 2.2994063\n",
      "Loss:6.257368087768555\n",
      "100 2.2824337\n",
      "Loss:6.05389928817749\n",
      "105 2.2756917\n",
      "Loss:6.10980749130249\n",
      "110 2.258445\n",
      "Loss:6.144439697265625\n",
      "115 2.2663589\n",
      "Loss:6.057452201843262\n",
      "120 2.276255\n",
      "Loss:6.246004104614258\n",
      "125 2.2846088\n",
      "Loss:6.00259256362915\n",
      "130 2.254604\n",
      "Loss:6.136509418487549\n",
      "135 2.2732036\n",
      "Loss:6.030725955963135\n",
      "140 2.2321677\n",
      "Loss:6.008901596069336\n",
      "145 2.253606\n",
      "Loss:6.043848991394043\n",
      "150 2.2560446\n",
      "Loss:5.94095516204834\n",
      "155 2.2718985\n",
      "Loss:5.8205084800720215\n",
      "160 2.250088\n",
      "Loss:6.041780948638916\n",
      "165 2.2351735\n",
      "Loss:6.15975284576416\n",
      "170 2.2549982\n",
      "Loss:5.616055011749268\n",
      "175 2.2557864\n",
      "Loss:6.027514457702637\n",
      "180 2.2084117\n",
      "Loss:5.980359077453613\n",
      "185 2.2127218\n",
      "Loss:6.024546146392822\n",
      "190 2.2431083\n",
      "Loss:6.137862682342529\n",
      "195 2.197838\n",
      "Loss:5.917989253997803\n",
      "200 2.264905\n",
      "Loss:5.628658294677734\n",
      "205 2.2182531\n",
      "Loss:5.97636079788208\n",
      "210 2.2238429\n",
      "Loss:6.003802299499512\n",
      "215 2.2166448\n",
      "Loss:6.16898775100708\n",
      "220 2.2366943\n",
      "Loss:6.244626522064209\n",
      "225 2.2384863\n",
      "Loss:5.894644260406494\n",
      "230 2.2129982\n",
      "Loss:6.0456156730651855\n",
      "235 2.1916964\n",
      "Loss:5.829082489013672\n",
      "240 2.218078\n",
      "Loss:6.088345527648926\n",
      "245 2.1681125\n",
      "Loss:5.767599105834961\n",
      "250 2.2019527\n",
      "Loss:5.947896957397461\n",
      "255 2.2100887\n",
      "Loss:5.973975658416748\n",
      "260 2.1669638\n",
      "Loss:5.852346420288086\n",
      "265 2.1959789\n",
      "Loss:5.948004722595215\n",
      "270 2.1835594\n",
      "Loss:5.932913780212402\n",
      "275 2.1963615\n",
      "Loss:5.847829818725586\n",
      "280 2.221844\n",
      "Loss:5.895568370819092\n",
      "285 2.193805\n",
      "Loss:5.962208271026611\n",
      "290 2.1935081\n",
      "Loss:5.982977390289307\n",
      "295 2.15738\n",
      "Loss:6.172712802886963\n",
      "300 2.1756582\n",
      "Loss:5.883572578430176\n",
      "305 2.1721168\n",
      "Loss:5.657617568969727\n",
      "310 2.1451101\n",
      "Loss:5.8805952072143555\n",
      "315 2.200367\n",
      "Loss:5.786862850189209\n",
      "320 2.190281\n",
      "Loss:5.864838600158691\n",
      "325 2.180776\n",
      "Loss:5.854720115661621\n",
      "330 2.1510675\n",
      "Loss:5.8158345222473145\n",
      "335 2.1908083\n",
      "Loss:5.729909420013428\n",
      "340 2.1795282\n",
      "Loss:5.651235103607178\n",
      "345 2.164391\n",
      "Loss:5.881805896759033\n",
      "350 2.1753056\n",
      "Loss:5.8408122062683105\n",
      "355 2.1579988\n",
      "Loss:5.754317760467529\n",
      "360 2.1424415\n",
      "Loss:5.785184860229492\n",
      "365 2.202036\n",
      "Loss:5.734706878662109\n",
      "370 2.1856177\n",
      "Loss:5.796265602111816\n",
      "375 2.1507175\n",
      "Loss:5.581161975860596\n",
      "380 2.1740324\n",
      "Loss:5.903685569763184\n",
      "385 2.1750855\n",
      "Loss:5.631952285766602\n",
      "390 2.1929784\n",
      "Loss:5.83085298538208\n",
      "395 2.142373\n",
      "Loss:5.834805965423584\n",
      "400 2.1392322\n",
      "Loss:5.930373191833496\n",
      "405 2.1576173\n",
      "Loss:5.580056667327881\n",
      "410 2.1863978\n",
      "Loss:5.727717399597168\n",
      "415 2.1455083\n",
      "Loss:5.600907325744629\n",
      "420 2.1232393\n",
      "Loss:5.880431652069092\n",
      "425 2.1550438\n",
      "Loss:6.02292537689209\n",
      "430 2.1420712\n",
      "Loss:5.81284761428833\n",
      "435 2.1475923\n",
      "Loss:5.543192386627197\n",
      "440 2.1259065\n",
      "Loss:5.909869194030762\n",
      "445 2.1516953\n",
      "Loss:5.9321722984313965\n",
      "450 2.1700783\n",
      "Loss:5.588659286499023\n",
      "455 2.1129477\n",
      "Loss:5.761199474334717\n",
      "460 2.171749\n",
      "Loss:5.797391891479492\n",
      "465 2.148292\n",
      "Loss:5.673401832580566\n",
      "470 2.1462173\n",
      "Loss:5.61259651184082\n",
      "475 2.1357014\n",
      "Loss:5.845942497253418\n",
      "480 2.1456158\n",
      "Loss:5.548401355743408\n",
      "485 2.1026864\n",
      "Loss:5.672369480133057\n",
      "490 2.1446562\n",
      "Loss:5.6743998527526855\n",
      "495 2.1634898\n",
      "Loss:5.633860111236572\n",
      "500 2.1131713\n",
      "Loss:5.7996721267700195\n",
      "505 2.1126328\n",
      "Loss:5.758418560028076\n",
      "510 2.125687\n",
      "Loss:5.879638671875\n",
      "515 2.107036\n",
      "Loss:5.649616718292236\n",
      "520 2.0674415\n",
      "Loss:5.5333428382873535\n",
      "525 2.1218407\n",
      "Loss:5.719844818115234\n",
      "530 2.1202414\n",
      "Loss:5.670884132385254\n",
      "535 2.0789282\n",
      "Loss:5.5851545333862305\n",
      "540 2.065751\n",
      "Loss:5.923795223236084\n",
      "545 2.1036146\n",
      "Loss:6.028368949890137\n",
      "550 2.0690377\n",
      "Loss:5.848719596862793\n",
      "555 2.1324196\n",
      "Loss:5.8701395988464355\n",
      "560 2.1033776\n",
      "Loss:5.5506157875061035\n",
      "565 2.0794833\n",
      "Loss:5.847497463226318\n",
      "570 2.0941262\n",
      "Loss:5.732299327850342\n",
      "575 2.1064143\n",
      "Loss:5.7882256507873535\n",
      "580 2.101405\n",
      "Loss:5.771909236907959\n",
      "585 2.0923274\n",
      "Loss:5.794194221496582\n",
      "590 2.0826936\n",
      "Loss:5.662519931793213\n",
      "595 2.0882826\n",
      "Loss:6.023331165313721\n",
      "600 2.1098592\n",
      "Loss:5.741822242736816\n",
      "605 2.0818233\n",
      "Loss:5.57571268081665\n",
      "610 2.0922527\n",
      "Loss:5.5532121658325195\n",
      "615 2.1024847\n",
      "Loss:5.575644016265869\n",
      "620 2.0954125\n",
      "Loss:5.690920829772949\n",
      "625 2.062619\n",
      "Loss:5.637424945831299\n",
      "630 2.116734\n",
      "Loss:5.854636192321777\n",
      "635 2.1154559\n",
      "Loss:5.659868240356445\n",
      "640 2.0976455\n",
      "Loss:5.547338008880615\n",
      "645 2.0704212\n",
      "Loss:5.611123085021973\n",
      "650 2.0886776\n",
      "Loss:5.662132263183594\n",
      "655 2.1080637\n",
      "Loss:5.756181716918945\n",
      "660 2.1042988\n",
      "Loss:5.716381549835205\n",
      "665 2.059725\n",
      "Loss:5.938292503356934\n",
      "670 2.084464\n",
      "Loss:5.850273609161377\n",
      "675 2.097855\n",
      "Loss:5.76234245300293\n",
      "680 2.1051817\n",
      "Loss:5.787694454193115\n",
      "685 2.1015308\n",
      "Loss:5.695390224456787\n",
      "690 2.1130025\n",
      "Loss:5.3268303871154785\n",
      "695 2.1030903\n",
      "Loss:5.779857158660889\n",
      "700 2.0835872\n",
      "Loss:5.735409259796143\n",
      "705 2.0522668\n",
      "Loss:5.496790885925293\n",
      "710 2.140955\n",
      "Loss:5.752048969268799\n",
      "715 2.1248524\n",
      "Loss:5.93947172164917\n",
      "720 2.0585637\n",
      "Loss:5.6849045753479\n",
      "725 2.084664\n",
      "Loss:5.8868327140808105\n",
      "730 2.0837514\n",
      "Loss:5.615996837615967\n",
      "735 2.0565293\n",
      "Loss:5.800031661987305\n",
      "740 2.0990968\n",
      "Loss:5.576553821563721\n",
      "745 2.0964997\n",
      "Loss:5.77353572845459\n",
      "750 2.051896\n",
      "Loss:5.9964680671691895\n",
      "755 2.1066585\n",
      "Loss:5.688272953033447\n",
      "760 2.0722675\n",
      "Loss:5.882737159729004\n",
      "765 2.087415\n",
      "Loss:5.863131523132324\n",
      "770 2.082678\n",
      "Loss:5.609022617340088\n",
      "775 2.0681539\n",
      "Loss:5.814375400543213\n",
      "780 2.0799308\n",
      "Loss:5.685898303985596\n",
      "785 2.093627\n",
      "Loss:5.52495002746582\n",
      "790 2.081222\n",
      "Loss:5.720198631286621\n",
      "795 2.1165853\n",
      "Loss:5.6084160804748535\n",
      "800 2.0986688\n",
      "Loss:5.577246189117432\n",
      "805 2.05562\n",
      "Loss:5.977406024932861\n",
      "810 2.0821917\n",
      "Loss:5.684350490570068\n",
      "815 2.0759163\n",
      "Loss:5.746778964996338\n",
      "820 2.0588334\n",
      "Loss:5.624750137329102\n",
      "825 2.0756714\n",
      "Loss:5.478674411773682\n",
      "830 2.0419104\n",
      "Loss:5.7144622802734375\n",
      "835 2.065493\n",
      "Loss:5.892602443695068\n",
      "840 2.089146\n",
      "Loss:5.433943748474121\n",
      "845 2.0813453\n",
      "Loss:5.640793800354004\n",
      "850 2.1026297\n",
      "Loss:5.68861198425293\n",
      "855 2.0847425\n",
      "Loss:5.602732181549072\n",
      "860 2.0897875\n",
      "Loss:5.79734992980957\n",
      "865 2.0768628\n",
      "Loss:5.59688663482666\n",
      "870 2.062363\n",
      "Loss:5.564352989196777\n",
      "875 2.041402\n",
      "Loss:5.65579891204834\n",
      "880 2.0846958\n",
      "Loss:5.5208940505981445\n",
      "885 2.0812984\n",
      "Loss:5.64728307723999\n",
      "890 2.0615122\n",
      "Loss:5.6283183097839355\n",
      "895 2.1227992\n",
      "Loss:5.721960544586182\n",
      "900 2.0482788\n",
      "Loss:5.548946857452393\n",
      "905 2.1015067\n",
      "Loss:5.440351486206055\n",
      "910 2.031733\n",
      "Loss:5.686977386474609\n",
      "915 2.0465\n",
      "Loss:5.740121841430664\n",
      "920 2.0658267\n",
      "Loss:5.730334758758545\n",
      "925 2.0590289\n",
      "Loss:5.606894016265869\n",
      "930 2.0420434\n",
      "Loss:5.875084400177002\n",
      "935 2.0676358\n",
      "Loss:5.902533531188965\n",
      "940 2.110343\n",
      "Loss:5.5381059646606445\n",
      "945 2.054875\n",
      "Loss:5.663651466369629\n",
      "950 2.072672\n",
      "Loss:5.784511089324951\n",
      "955 2.0553503\n",
      "Loss:5.671206474304199\n",
      "960 2.123867\n",
      "Loss:5.877270221710205\n",
      "965 2.0850008\n",
      "Loss:5.566680431365967\n",
      "970 2.056191\n",
      "Loss:5.115341663360596\n",
      "975 2.06205\n",
      "Loss:5.613008975982666\n",
      "980 2.1146288\n",
      "Loss:5.683292388916016\n",
      "985 2.07214\n",
      "Loss:5.590439796447754\n",
      "990 2.0386887\n",
      "Loss:5.7034149169921875\n",
      "995 2.0977628\n",
      "Loss:5.574538230895996\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "R2: -10.212228276257308\n",
      "MSE: 6.382979\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = X_train.shape[1]\n",
    "# Neural Network Parameters\n",
    "\n",
    "X_tensor_train = X_tensor_train.cuda()\n",
    "X_tensor_test = X_tensor_test.cuda()\n",
    "y_tensor_train = y_tensor_train.cuda()\n",
    "y_tensor_test = y_tensor_test.cuda()\n",
    "\n",
    "dropout_proba = 0.3\n",
    "lr = 0.001\n",
    "momentum = 0.33\n",
    "dropout = torch.nn.Dropout(p=1 - (dropout_proba))\n",
    "dropout = dropout.cuda()\n",
    "# Hidden Layers\n",
    "\n",
    "hiddenLayer_1=5000\n",
    "hiddenLayer_2=1000\n",
    "hiddenLayer_3=200\n",
    "hiddenLayer_4=10\n",
    "\n",
    "# NN Layers\n",
    "\n",
    "linear_1=torch.nn.Linear(N_FEATURES, hiddenLayer_1, bias=True)\n",
    "linear_2=torch.nn.Linear(hiddenLayer_1, hiddenLayer_2)\n",
    "linear_3=torch.nn.Linear(hiddenLayer_2, hiddenLayer_3)\n",
    "linear_4=torch.nn.Linear(hiddenLayer_3, hiddenLayer_4)\n",
    "linear_5=torch.nn.Linear(hiddenLayer_4, 1)\n",
    "\n",
    "linear_1 = linear_1.cuda()\n",
    "linear_2 = linear_2.cuda()\n",
    "linear_3 = linear_3.cuda()\n",
    "linear_4 = linear_4.cuda()\n",
    "linear_5 = linear_5.cuda()\n",
    "\n",
    "# Activation Functions\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "# threshold = nn.Threshold(0.5, 0)\n",
    "# tanh= torch.nn.Tanh()\n",
    "relu= torch.nn.ReLU()\n",
    "# softmax = torch.nn.Softmax()\n",
    "\n",
    "relu = relu.cuda()\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "model = nn.Sequential(linear_1,nn.BatchNorm1d(hiddenLayer_1),relu,\n",
    "                          linear_2,dropout,relu,\n",
    "                          linear_3,dropout,relu,\n",
    "                          linear_4,dropout,relu,\n",
    "                          linear_5,dropout,relu,\n",
    "                          relu\n",
    "                          #sigmoid\n",
    "                          )\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "loss_function=torch.nn.L1Loss()\n",
    "epochs = 1000\n",
    "losses = []\n",
    "# model.to(torch.device(\"cuda:0\"))\n",
    "model = model.cuda()\n",
    "# optimizer = optimizer.cuda()\n",
    "# loss_function = loss_function.cuda()\n",
    "\n",
    "for step in range(epochs):    \n",
    "    out = model(X_tensor_train) \n",
    "    # y_tensor_train = tf.squeeze(y_tensor_train)\n",
    "    target = y_tensor_train\n",
    "    # target = target.unsqueeze(1)\n",
    "    # target = target.float()\n",
    "    cost = loss_function(out, target) \n",
    "    optimizer.zero_grad()  \n",
    "    # BackProp \n",
    "    cost.backward()   \n",
    "    # adjusting the weights     \n",
    "    optimizer.step()         \n",
    "        \n",
    "    if step % 5 == 0:        \n",
    "        loss = cost.data\n",
    "        losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())        \n",
    "        prediction = (model(X_tensor_test).data).float()      \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = y_tensor_test.cpu().data.numpy()\n",
    "        print(\"Loss:\" + str(torch.mean((y_tensor_test.cpu() - pred_y) **2).detach().item()))\n",
    "\n",
    "\n",
    "print(\"--\"*25)\n",
    "# Graph\n",
    "%matplotlib inline\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "pred_y = pred_y > 0.5\n",
    "# print('f1 score', f1_score(target_y, pred_y))\n",
    "\n",
    "print(\"--\"*25)\n",
    "# R2 \n",
    "print('R2:',r2_score(target_y, pred_y))\n",
    "print(\"MSE:\",mean_squared_error(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5DJPoUo3LJj"
   },
   "source": [
    "#### For `dropout` = 0.1, `learning rate` = 0.01, `momentum` = 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l28D_33U2l4Y",
    "outputId": "0a390f54-372f-4422-f817-fa4dc26b1b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.8031907\n",
      "Loss:8.325757026672363\n",
      "5 3.1436648\n",
      "Loss:12.261579513549805\n",
      "10 2.8878775\n",
      "Loss:21.180015563964844\n",
      "15 2.8557813\n",
      "Loss:14.573310852050781\n",
      "20 2.8785572\n",
      "Loss:7.824872970581055\n",
      "25 2.7776792\n",
      "Loss:7.793097019195557\n",
      "30 2.7878811\n",
      "Loss:7.843174934387207\n",
      "35 2.7823198\n",
      "Loss:11.130971908569336\n",
      "40 2.7648954\n",
      "Loss:7.78898811340332\n",
      "45 2.7729442\n",
      "Loss:11.882404327392578\n",
      "50 2.7826579\n",
      "Loss:7.916173934936523\n",
      "55 2.7723186\n",
      "Loss:7.783181667327881\n",
      "60 2.7696605\n",
      "Loss:7.8477582931518555\n",
      "65 2.7619743\n",
      "Loss:7.78711462020874\n",
      "70 2.7678297\n",
      "Loss:7.9463911056518555\n",
      "75 2.764231\n",
      "Loss:7.777744770050049\n",
      "80 2.7682025\n",
      "Loss:8.072833061218262\n",
      "85 2.770218\n",
      "Loss:7.78538703918457\n",
      "90 2.7634723\n",
      "Loss:7.770163536071777\n",
      "95 2.7700589\n",
      "Loss:7.780951499938965\n",
      "100 2.761341\n",
      "Loss:7.770302772521973\n",
      "105 2.7596319\n",
      "Loss:7.760559558868408\n",
      "110 2.7631361\n",
      "Loss:7.787613868713379\n",
      "115 2.7780933\n",
      "Loss:7.76967191696167\n",
      "120 2.7614572\n",
      "Loss:7.75986909866333\n",
      "125 2.7630537\n",
      "Loss:7.785386562347412\n",
      "130 2.7691395\n",
      "Loss:7.742452621459961\n",
      "135 2.7604945\n",
      "Loss:7.771050930023193\n",
      "140 2.762884\n",
      "Loss:7.83476448059082\n",
      "145 2.7830296\n",
      "Loss:7.768328666687012\n",
      "150 2.7708075\n",
      "Loss:7.7728657722473145\n",
      "155 2.7612755\n",
      "Loss:7.738544464111328\n",
      "160 2.7597873\n",
      "Loss:7.794326305389404\n",
      "165 2.7730148\n",
      "Loss:7.733362674713135\n",
      "170 2.760545\n",
      "Loss:7.751651287078857\n",
      "175 2.76517\n",
      "Loss:7.748762130737305\n",
      "180 2.7548187\n",
      "Loss:7.792827606201172\n",
      "185 2.757631\n",
      "Loss:7.8285393714904785\n",
      "190 2.7574408\n",
      "Loss:7.720649719238281\n",
      "195 2.7580445\n",
      "Loss:7.724802494049072\n",
      "200 2.7640138\n",
      "Loss:7.716182231903076\n",
      "205 2.7553566\n",
      "Loss:7.730624675750732\n",
      "210 2.7515562\n",
      "Loss:7.793808460235596\n",
      "215 2.7487454\n",
      "Loss:7.759276866912842\n",
      "220 2.7624714\n",
      "Loss:7.7333526611328125\n",
      "225 2.752944\n",
      "Loss:7.696524620056152\n",
      "230 2.7503917\n",
      "Loss:8.013290405273438\n",
      "235 2.7437646\n",
      "Loss:7.754818439483643\n",
      "240 2.7486994\n",
      "Loss:7.637116432189941\n",
      "245 2.7231019\n",
      "Loss:7.625765323638916\n",
      "250 2.7266707\n",
      "Loss:7.5914788246154785\n",
      "255 2.7036781\n",
      "Loss:7.500524997711182\n",
      "260 2.7019846\n",
      "Loss:7.4861369132995605\n",
      "265 2.6749792\n",
      "Loss:7.415922164916992\n",
      "270 2.6760867\n",
      "Loss:7.385440826416016\n",
      "275 2.6699462\n",
      "Loss:7.265061378479004\n",
      "280 2.6367457\n",
      "Loss:7.348900318145752\n",
      "285 2.6324196\n",
      "Loss:7.209245204925537\n",
      "290 2.631838\n",
      "Loss:7.291590213775635\n",
      "295 2.6169865\n",
      "Loss:7.215518951416016\n",
      "300 2.5949757\n",
      "Loss:7.1151838302612305\n",
      "305 2.6148038\n",
      "Loss:7.4474310874938965\n",
      "310 2.5988314\n",
      "Loss:7.101056098937988\n",
      "315 2.590737\n",
      "Loss:7.169939041137695\n",
      "320 2.5890489\n",
      "Loss:6.922088623046875\n",
      "325 2.5692477\n",
      "Loss:7.282609462738037\n",
      "330 2.5876372\n",
      "Loss:6.91377067565918\n",
      "335 2.567691\n",
      "Loss:7.085268497467041\n",
      "340 2.5682514\n",
      "Loss:7.065494537353516\n",
      "345 2.5754678\n",
      "Loss:7.113742351531982\n",
      "350 2.5629594\n",
      "Loss:7.161914348602295\n",
      "355 2.5538528\n",
      "Loss:7.210047245025635\n",
      "360 2.5481403\n",
      "Loss:7.132430076599121\n",
      "365 2.580725\n",
      "Loss:7.105205059051514\n",
      "370 2.546244\n",
      "Loss:7.068661689758301\n",
      "375 2.5601864\n",
      "Loss:7.141678333282471\n",
      "380 2.5611708\n",
      "Loss:6.992062091827393\n",
      "385 2.5725143\n",
      "Loss:7.001419544219971\n",
      "390 2.5543652\n",
      "Loss:7.065504550933838\n",
      "395 2.549026\n",
      "Loss:6.9832305908203125\n",
      "400 2.5499263\n",
      "Loss:6.876328945159912\n",
      "405 2.540128\n",
      "Loss:7.195810317993164\n",
      "410 2.5664773\n",
      "Loss:7.020934104919434\n",
      "415 2.562454\n",
      "Loss:6.9456257820129395\n",
      "420 2.5256844\n",
      "Loss:7.162861347198486\n",
      "425 2.5405164\n",
      "Loss:7.023926734924316\n",
      "430 2.5607662\n",
      "Loss:6.747401714324951\n",
      "435 2.5322626\n",
      "Loss:6.908550262451172\n",
      "440 2.5479887\n",
      "Loss:7.1895833015441895\n",
      "445 2.5362415\n",
      "Loss:7.162564277648926\n",
      "450 2.5300534\n",
      "Loss:7.022940635681152\n",
      "455 2.5376813\n",
      "Loss:7.1626787185668945\n",
      "460 2.5438652\n",
      "Loss:7.1366448402404785\n",
      "465 2.5435936\n",
      "Loss:7.0485944747924805\n",
      "470 2.542941\n",
      "Loss:7.1116943359375\n",
      "475 2.5070453\n",
      "Loss:6.9344916343688965\n",
      "480 2.5343215\n",
      "Loss:7.086644649505615\n",
      "485 2.5117388\n",
      "Loss:6.9736433029174805\n",
      "490 2.5187953\n",
      "Loss:7.111814498901367\n",
      "495 2.560881\n",
      "Loss:7.1750335693359375\n",
      "500 2.51495\n",
      "Loss:7.099233627319336\n",
      "505 2.5484262\n",
      "Loss:7.086511611938477\n",
      "510 2.5324738\n",
      "Loss:7.124724864959717\n",
      "515 2.5582643\n",
      "Loss:7.099185466766357\n",
      "520 2.5452797\n",
      "Loss:7.010771751403809\n",
      "525 2.5535047\n",
      "Loss:7.162466049194336\n",
      "530 2.512947\n",
      "Loss:7.149770736694336\n",
      "535 2.5524435\n",
      "Loss:7.010641574859619\n",
      "540 2.5164435\n",
      "Loss:7.099175930023193\n",
      "545 2.5466423\n",
      "Loss:7.03599214553833\n",
      "550 2.5444713\n",
      "Loss:7.339409351348877\n",
      "555 2.569838\n",
      "Loss:6.998199462890625\n",
      "560 2.5359929\n",
      "Loss:7.213017463684082\n",
      "565 2.506785\n",
      "Loss:7.023309230804443\n",
      "570 2.5288436\n",
      "Loss:6.884350299835205\n",
      "575 2.4920957\n",
      "Loss:7.238170146942139\n",
      "580 2.5116\n",
      "Loss:6.985414981842041\n",
      "585 2.5341983\n",
      "Loss:6.9853835105896\n",
      "590 2.5471256\n",
      "Loss:6.998167037963867\n",
      "595 2.5534043\n",
      "Loss:7.035833358764648\n",
      "600 2.543549\n",
      "Loss:7.187641620635986\n",
      "605 2.5652244\n",
      "Loss:7.162559509277344\n",
      "610 2.5591128\n",
      "Loss:7.124361991882324\n",
      "615 2.5746737\n",
      "Loss:7.1119608879089355\n",
      "620 2.5227056\n",
      "Loss:7.0992350578308105\n",
      "625 2.543532\n",
      "Loss:7.124372959136963\n",
      "630 2.5275118\n",
      "Loss:6.960268974304199\n",
      "635 2.5310888\n",
      "Loss:7.073978424072266\n",
      "640 2.5551298\n",
      "Loss:7.073871612548828\n",
      "645 2.5213237\n",
      "Loss:6.947569370269775\n",
      "650 2.5576842\n",
      "Loss:7.225673198699951\n",
      "655 2.5205317\n",
      "Loss:6.96012544631958\n",
      "660 2.5404391\n",
      "Loss:7.212939739227295\n",
      "665 2.5337732\n",
      "Loss:7.06133508682251\n",
      "670 2.52841\n",
      "Loss:7.200382232666016\n",
      "675 2.5310655\n",
      "Loss:7.13714075088501\n",
      "680 2.5674362\n",
      "Loss:7.124487400054932\n",
      "685 2.5492744\n",
      "Loss:6.960232257843018\n",
      "690 2.549758\n",
      "Loss:7.06125020980835\n",
      "695 2.5266223\n",
      "Loss:7.111865043640137\n",
      "700 2.506285\n",
      "Loss:7.010617256164551\n",
      "705 2.5404415\n",
      "Loss:7.263510227203369\n",
      "710 2.5496922\n",
      "Loss:7.111804485321045\n",
      "715 2.5572474\n",
      "Loss:7.036073207855225\n",
      "720 2.5470386\n",
      "Loss:7.162525653839111\n",
      "725 2.5512028\n",
      "Loss:6.985141277313232\n",
      "730 2.5363889\n",
      "Loss:7.162598133087158\n",
      "735 2.5448651\n",
      "Loss:6.95998477935791\n",
      "740 2.5417838\n",
      "Loss:7.124556064605713\n",
      "745 2.5536842\n",
      "Loss:7.0107421875\n",
      "750 2.5452816\n",
      "Loss:6.998142242431641\n",
      "755 2.520484\n",
      "Loss:7.099160194396973\n",
      "760 2.5222142\n",
      "Loss:6.9348673820495605\n",
      "765 2.5678825\n",
      "Loss:6.8465800285339355\n",
      "770 2.5032506\n",
      "Loss:7.25084114074707\n",
      "775 2.5222452\n",
      "Loss:7.200326919555664\n",
      "780 2.5214338\n",
      "Loss:7.162308692932129\n",
      "785 2.5190876\n",
      "Loss:7.086584568023682\n",
      "790 2.5501342\n",
      "Loss:6.9727959632873535\n",
      "795 2.5315204\n",
      "Loss:7.023416042327881\n",
      "800 2.5715015\n",
      "Loss:7.200214862823486\n",
      "805 2.5627007\n",
      "Loss:7.2762451171875\n",
      "810 2.5506842\n",
      "Loss:7.073880195617676\n",
      "815 2.508913\n",
      "Loss:7.073975086212158\n",
      "820 2.5537786\n",
      "Loss:7.212854862213135\n",
      "825 2.527688\n",
      "Loss:7.137231349945068\n",
      "830 2.520557\n",
      "Loss:7.17495584487915\n",
      "835 2.5635047\n",
      "Loss:7.023304462432861\n",
      "840 2.52808\n",
      "Loss:7.212952136993408\n",
      "845 2.5466256\n",
      "Loss:7.326623916625977\n",
      "850 2.512474\n",
      "Loss:7.074040412902832\n",
      "855 2.5330274\n",
      "Loss:7.010472297668457\n",
      "860 2.5000682\n",
      "Loss:6.897180557250977\n",
      "865 2.5258207\n",
      "Loss:7.149696350097656\n",
      "870 2.5506024\n",
      "Loss:6.985428810119629\n",
      "875 2.5164447\n",
      "Loss:7.086635589599609\n",
      "880 2.5204144\n",
      "Loss:7.010809421539307\n",
      "885 2.5457382\n",
      "Loss:7.023433208465576\n",
      "890 2.54446\n",
      "Loss:7.288797378540039\n",
      "895 2.532404\n",
      "Loss:7.0738935470581055\n",
      "900 2.5386164\n",
      "Loss:7.124445915222168\n",
      "905 2.5430458\n",
      "Loss:7.111879825592041\n",
      "910 2.5510209\n",
      "Loss:7.111846923828125\n",
      "915 2.5431023\n",
      "Loss:6.985307216644287\n",
      "920 2.5324826\n",
      "Loss:7.238336086273193\n",
      "925 2.5014052\n",
      "Loss:7.124533176422119\n",
      "930 2.5516279\n",
      "Loss:7.12432861328125\n",
      "935 2.5461571\n",
      "Loss:7.03601598739624\n",
      "940 2.571897\n",
      "Loss:7.035976409912109\n",
      "945 2.5310814\n",
      "Loss:7.02344274520874\n",
      "950 2.521766\n",
      "Loss:7.048661231994629\n",
      "955 2.5186665\n",
      "Loss:6.9474968910217285\n",
      "960 2.5448322\n",
      "Loss:7.213009357452393\n",
      "965 2.5168867\n",
      "Loss:7.2130608558654785\n",
      "970 2.5387735\n",
      "Loss:7.111578941345215\n",
      "975 2.555064\n",
      "Loss:6.998182773590088\n",
      "980 2.5244277\n",
      "Loss:7.023458957672119\n",
      "985 2.5178165\n",
      "Loss:7.162405967712402\n",
      "990 2.5568495\n",
      "Loss:7.149719715118408\n",
      "995 2.5550368\n",
      "Loss:7.035922527313232\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "R2: -11.925207596241064\n",
      "MSE: 7.358156\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = X_train.shape[1]\n",
    "# Neural Network Parameters\n",
    "\n",
    "X_tensor_train = X_tensor_train.cuda()\n",
    "X_tensor_test = X_tensor_test.cuda()\n",
    "y_tensor_train = y_tensor_train.cuda()\n",
    "y_tensor_test = y_tensor_test.cuda()\n",
    "\n",
    "dropout_proba = 0.1\n",
    "lr = 0.001\n",
    "momentum = 0.11\n",
    "dropout = torch.nn.Dropout(p=1 - (dropout_proba))\n",
    "dropout = dropout.cuda()\n",
    "# Hidden Layers\n",
    "\n",
    "hiddenLayer_1=5000\n",
    "hiddenLayer_2=1000\n",
    "hiddenLayer_3=200\n",
    "hiddenLayer_4=10\n",
    "\n",
    "# NN Layers\n",
    "\n",
    "linear_1=torch.nn.Linear(N_FEATURES, hiddenLayer_1, bias=True)\n",
    "linear_2=torch.nn.Linear(hiddenLayer_1, hiddenLayer_2)\n",
    "linear_3=torch.nn.Linear(hiddenLayer_2, hiddenLayer_3)\n",
    "linear_4=torch.nn.Linear(hiddenLayer_3, hiddenLayer_4)\n",
    "linear_5=torch.nn.Linear(hiddenLayer_4, 1)\n",
    "\n",
    "linear_1 = linear_1.cuda()\n",
    "linear_2 = linear_2.cuda()\n",
    "linear_3 = linear_3.cuda()\n",
    "linear_4 = linear_4.cuda()\n",
    "linear_5 = linear_5.cuda()\n",
    "\n",
    "# Activation Functions\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "# threshold = nn.Threshold(0.5, 0)\n",
    "# tanh= torch.nn.Tanh()\n",
    "relu= torch.nn.ReLU()\n",
    "# softmax = torch.nn.Softmax()\n",
    "\n",
    "relu = relu.cuda()\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "model = nn.Sequential(linear_1,nn.BatchNorm1d(hiddenLayer_1),relu,\n",
    "                          linear_2,dropout,relu,\n",
    "                          linear_3,dropout,relu,\n",
    "                          linear_4,dropout,relu,\n",
    "                          linear_5,dropout,relu,\n",
    "                          relu\n",
    "                          #sigmoid\n",
    "                          )\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "loss_function=torch.nn.L1Loss()\n",
    "epochs = 1000\n",
    "losses = []\n",
    "# model.to(torch.device(\"cuda:0\"))\n",
    "model = model.cuda()\n",
    "# optimizer = optimizer.cuda()\n",
    "# loss_function = loss_function.cuda()\n",
    "\n",
    "for step in range(epochs):    \n",
    "    out = model(X_tensor_train) \n",
    "    # y_tensor_train = tf.squeeze(y_tensor_train)\n",
    "    target = y_tensor_train\n",
    "    # target = target.unsqueeze(1)\n",
    "    # target = target.float()\n",
    "    cost = loss_function(out, target) \n",
    "    optimizer.zero_grad()  \n",
    "    # BackProp \n",
    "    cost.backward()   \n",
    "    # adjusting the weights     \n",
    "    optimizer.step()         \n",
    "        \n",
    "    if step % 5 == 0:        \n",
    "        loss = cost.data\n",
    "        losses.append(loss)\n",
    "        print(step, cost.data.cpu().numpy())        \n",
    "        prediction = (model(X_tensor_test).data).float()      \n",
    "        pred_y = prediction.cpu().numpy().squeeze()\n",
    "        target_y = y_tensor_test.cpu().data.numpy()\n",
    "        print(\"Loss:\" + str(torch.mean((y_tensor_test.cpu() - pred_y) **2).detach().item()))\n",
    "\n",
    "\n",
    "print(\"--\"*25)\n",
    "# Graph\n",
    "%matplotlib inline\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "pred_y = pred_y > 0.5\n",
    "# print('f1 score', f1_score(target_y, pred_y))\n",
    "\n",
    "print(\"--\"*25)\n",
    "# R2 \n",
    "print('R2:',r2_score(target_y, pred_y))\n",
    "print(\"MSE:\",mean_squared_error(target_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUkvkNwbP4x_"
   },
   "source": [
    "## Discussion\n",
    "\n",
    "It is not mathematically impossible to have a negative R2 score. It simply implies that our model, with all of its constants, does not suit the data well, and as a result, we implemented the Support Vector Regressor and Random Forest Regressor models."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TrainingDNN-checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
